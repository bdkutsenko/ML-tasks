{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RNNs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9nAPlp4iIK_s"},"source":["# Задание 6: Рекуррентные нейронные сети (RNNs)\n","\n","Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P59NYU98GCb9","executionInfo":{"status":"ok","timestamp":1620467015027,"user_tz":-420,"elapsed":16180,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"c67d3f74-6fd7-45ae-f72d-d1edf74154ba"},"source":["!pip3 -qq install torch==1.8.1\n","!pip3 -qq install bokeh==2.3.1\n","!pip3 -qq install gensim==3.6.0\n","!pip3 -qq install nltk\n","!pip3 -qq install scikit-learn==0.20.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 5.4MB 6.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8sVtGHmA9aBM"},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","if torch.cuda.is_available():\n","    from torch.cuda import FloatTensor, LongTensor\n","else:\n","    from torch import FloatTensor, LongTensor\n","\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6CNKM3b4hT1"},"source":["# Рекуррентные нейронные сети (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"O_XkoGNQUeGm"},"source":["## POS Tagging"]},{"cell_type":"markdown","metadata":{"id":"QFEtWrS_4rUs"},"source":["Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n","\n","![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n","\n","*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n","\n","Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n","\n","Мы порешаем сейчас POS Tagging для английского.\n","\n","Будем работать с таким набором тегов:\n","- ADJ - adjective (new, good, high, ...)\n","- ADP - adposition (on, of, at, ...)\n","- ADV - adverb (really, already, still, ...)\n","- CONJ - conjunction (and, or, but, ...)\n","- DET - determiner, article (the, a, some, ...)\n","- NOUN - noun (year, home, costs, ...)\n","- NUM - numeral (twenty-four, fourth, 1991, ...)\n","- PRT - particle (at, on, out, ...)\n","- PRON - pronoun (he, their, her, ...)\n","- VERB - verb (is, say, told, ...)\n","- . - punctuation marks (. , ;)\n","- X - other (ersatz, esprit, dunno, ...)"]},{"cell_type":"markdown","metadata":{"id":"EPIkKdFlHB-X"},"source":["Скачаем данные:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiA2dGmgF1rW","executionInfo":{"status":"ok","timestamp":1620467038675,"user_tz":-420,"elapsed":2446,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"f22b4bb3-6588-4c78-bdb1-3a713c03dc9a"},"source":["import nltk\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d93g_swyJA_V"},"source":["Пример размеченного предложения:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QstS4NO0L97c","executionInfo":{"status":"ok","timestamp":1620467041011,"user_tz":-420,"elapsed":646,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"aebafff4-ff5a-4290-c549-3596532a5f7b"},"source":["for word, tag in data[0]:\n","    print('{:15}\\t{}'.format(word, tag))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The            \tDET\n","Fulton         \tNOUN\n","County         \tNOUN\n","Grand          \tADJ\n","Jury           \tNOUN\n","said           \tVERB\n","Friday         \tNOUN\n","an             \tDET\n","investigation  \tNOUN\n","of             \tADP\n","Atlanta's      \tNOUN\n","recent         \tADJ\n","primary        \tNOUN\n","election       \tNOUN\n","produced       \tVERB\n","``             \t.\n","no             \tDET\n","evidence       \tNOUN\n","''             \t.\n","that           \tADP\n","any            \tDET\n","irregularities \tNOUN\n","took           \tVERB\n","place          \tNOUN\n",".              \t.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"epdW8u_YXcAv"},"source":["Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n","\n","На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTai8Ta0lgwL","executionInfo":{"status":"ok","timestamp":1620467067226,"user_tz":-420,"elapsed":24170,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"0e999b34-2ceb-4802-f9d9-5c715881cfe7"},"source":["train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n","\n","print('Words count in train set:', sum(len(sent) for sent in train_data))\n","print('Words count in val set:', sum(len(sent) for sent in val_data))\n","print('Words count in test set:', sum(len(sent) for sent in test_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Words count in train set: 739769\n","Words count in val set: 130954\n","Words count in test set: 290469\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eChdLNGtXyP0"},"source":["Построим маппинги из слов в индекс и из тега в индекс:\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCjwwDs6Zq9x","executionInfo":{"status":"ok","timestamp":1620467190561,"user_tz":-420,"elapsed":1066,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"6028682f-cec5-4911-8ebc-bc850c8babbe"},"source":["words = {word for sample in train_data for word, tag in sample}\n","word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n","word2ind['<pad>'] = 0\n","\n","tags = {tag for sample in train_data for word, tag in sample}\n","tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n","tag2ind['<pad>'] = 0\n","\n","print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique words in train = 45441. Tags = {'VERB', 'CONJ', 'ADV', 'DET', 'NOUN', 'X', '.', 'ADJ', 'PRON', 'PRT', 'NUM', 'ADP'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"URC1B2nvPGFt","executionInfo":{"elapsed":21371,"status":"ok","timestamp":1620374118698,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"},"user_tz":-420},"outputId":"003265cc-7b26-4d08-a58f-18ba0b6859b8"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from collections import Counter\n","\n","tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n","tag_distribution = [tag_distribution[tag] for tag in tags]\n","\n","plt.figure(figsize=(10, 5))\n","\n","bar_width = 0.35\n","plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n","plt.xticks(np.arange(len(tags)), tags)\n","    \n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gArQwbzWWkgi"},"source":["## Бейзлайн\n","\n","Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n","\n","![tag-context](https://www.nltk.org/images/tag-context.png)  \n","*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n","\n","На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n","\n","Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n","\n","Простейший вариант - униграммная модель, учитывающая только слово:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rWmSToIaeAo","executionInfo":{"status":"ok","timestamp":1620484587178,"user_tz":-420,"elapsed":4675,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"2094a405-a1b7-4c08-b9ff-8632f29212db"},"source":["import nltk\n","\n","default_tagger = nltk.DefaultTagger('NN')\n","\n","unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n","print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of unigram tagger = 92.62%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"07Ymb_MkbWsF"},"source":["Добавим вероятности переходов:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjz_Rk0bbMyH","executionInfo":{"status":"ok","timestamp":1620484594294,"user_tz":-420,"elapsed":5709,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"82f31866-d7b7-4f21-c3b6-fe27fa305698"},"source":["bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n","print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of bigram tagger = 93.42%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uWMw6QHvbaDd"},"source":["Обратите внимание, что `backoff` важен:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XCuxEBVbOY_","executionInfo":{"elapsed":5494,"status":"ok","timestamp":1620280478469,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"},"user_tz":-420},"outputId":"32ddac35-1c77-48f0-d465-ba1e12b8ff0d"},"source":["trigram_tagger = nltk.TrigramTagger(train_data)\n","print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of trigram tagger = 23.33%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4t3xyYd__8d-"},"source":["## Увеличиваем контекст с рекуррентными сетями\n","\n","Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n","\n","Омонимия - основная причина, почему униграмная модель плоха:  \n","*“he cashed a check at the **bank**”*  \n","vs  \n","*“he sat on the **bank** of the river”*\n","\n","Поэтому нам очень полезно учитывать контекст при предсказании тега.\n","\n","Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n","\n","![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n","\n","Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."]},{"cell_type":"code","metadata":{"id":"RtRbz1SwgEqc"},"source":["def convert_data(data, word2ind, tag2ind):\n","    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n","    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n","    \n","    return X, y\n","\n","X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n","X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n","X_test, y_test = convert_data(test_data, word2ind, tag2ind)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhsTKZalfih6"},"source":["def iterate_batches(data, batch_size):\n","    X, y = data\n","    n_samples = len(X)\n","\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n_samples, batch_size):\n","        end = min(start + batch_size, n_samples)\n","        \n","        batch_indices = indices[start:end]\n","        \n","        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n","        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        \n","        for batch_ind, sample_ind in enumerate(batch_indices):\n","            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n","            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n","            \n","        yield X_batch, y_batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4XsRII5kW5x","executionInfo":{"elapsed":628,"status":"ok","timestamp":1620364573661,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"},"user_tz":-420},"outputId":"6fe4fb49-68c7-44bf-8609-82bfe0050ab6"},"source":["X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n","\n","X_batch.shape, y_batch.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 4), (32, 4))"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"C5I9E9P6eFYv"},"source":["**Задание** Реализуйте `LSTMTagger`:"]},{"cell_type":"code","metadata":{"id":"WVEHju54d68T"},"source":["class LSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.lstm_hidden_dim = lstm_hidden_dim\n","        self.lstm_layers_count = lstm_layers_count\n","        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim)\n","        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n","\n","    def forward(self, inputs):\n","        tag_scores=[]\n","        for i in range(len(inputs)):\n","          embeds = self.word_embeddings(inputs[i])\n","          lstm_out, _ = self.lstm(embeds.view(len(inputs[i]), 1, -1))\n","          tag_space = self.hidden2tag(lstm_out.view(len(inputs[i]), -1))\n","          tag_scores.append(F.log_softmax(tag_space, dim=1))\n","        return torch.transpose(torch.stack(tag_scores,0),1,2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_HA8zyheYGH"},"source":["**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"]},{"cell_type":"code","metadata":{"id":"5FyWNv0ch_gr"},"source":["def accuracy_lstm_sklearn(y_batch, target):\n","  accuracy = 0\n","  for i in range(len(y_batch[:,0])):\n","    accuracy+= sklearn.metrics.accuracy_score(y_batch[i,:], target[i,:])/len(y_batch[:,0])\n","  return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DQU6BZ5KYcS"},"source":["def accuracy_lstm(y_batch, target):\n","  #DONE Masking implemented\n","  _, target = torch.max(logits, 1)\n","  cur_correct_count = torch.sum((y_batch==target)*((y_batch!=0).type(torch.uint8)))\n","  cur_sum_count = torch.sum((target!=0)*((y_batch!=0).type(torch.uint8)))\n","  return cur_correct_count/cur_sum_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbrxsZ2mehWB","executionInfo":{"elapsed":1047,"status":"ok","timestamp":1620371758894,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"},"user_tz":-420},"outputId":"51ab5759-3d91-48de-8cde-1a79ea92e43e"},"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",")\n","\n","X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n","\n","logits = model(X_batch)\n","_, target = torch.max(logits, 1)\n","#DONE Calculate accuracy\n","\n","\n","accuracy = accuracy_lstm(y_batch,target)\n","print('Accuracy of untrained lstm tagger = {:.2%}'.format(accuracy))\n","#accuracy = accuracy_lstm_sklearn(y_batch,target)\n","#print('Accuracy of untrained lstm tagger = {:.2%}'.format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of untrained lstm tagger = 5.35%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GMUyUm1hgpe3"},"source":["#DONE loss calculation\n","logits = model(X_batch)\n","criterion = nn.CrossEntropyLoss()\n","loss = criterion(logits, y_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nSgV3NPUpcjH"},"source":["**Задание** Вставьте эти вычисление в функцию:"]},{"cell_type":"code","metadata":{"id":"FprPQ0gllo7b"},"source":["import math\n","from tqdm import tqdm\n","\n","\n","def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n","    epoch_loss = 0\n","    correct_count = 0\n","    sum_count = 0\n","    \n","    is_train = not optimizer is None\n","    name = name or ''\n","    model.train(is_train)\n","    \n","    batches_count = math.ceil(len(data[0]) / batch_size)\n","    with torch.autograd.set_grad_enabled(is_train):\n","        with tqdm(total=batches_count) as progress_bar:\n","            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n","                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n","                logits = model(X_batch)\n","\n","                loss = criterion(logits, y_batch)\n","\n","                epoch_loss += loss.item()\n","\n","                if optimizer:\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                _, target = torch.max(logits, 1)\n","                cur_correct_count = torch.sum((y_batch==target)*((y_batch!=0).type(torch.uint8)))\n","                cur_sum_count = torch.sum((target!=0)*((y_batch!=0).type(torch.uint8)))\n","                \n","                correct_count += cur_correct_count\n","                sum_count += cur_sum_count\n","\n","                progress_bar.update()\n","                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(           \n","                  name, loss.item(), cur_correct_count / cur_sum_count)\n","                )\n","                \n","            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                name, epoch_loss / batches_count, correct_count / sum_count)\n","            )\n","\n","    return epoch_loss / batches_count, correct_count / sum_count\n","\n","\n","def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n","        val_data=None, val_batch_size=None):\n","        \n","    if not val_data is None and val_batch_size is None:\n","        val_batch_size = batch_size\n","        \n","    for epoch in range(epochs_count):\n","        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n","        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n","        \n","        if not val_data is None:\n","            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqfbeh1ltEYa","executionInfo":{"status":"ok","timestamp":1620462494831,"user_tz":-420,"elapsed":850513,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"8fbbf079-e44a-45a2-8e23-a4dd24f8babe"},"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0).cuda()\n","optimizer = optim.Adam(model.parameters(),lr=5e-3)\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 / 10] Train: Loss = 0.39525, Accuracy = 86.56%: 100%|██████████| 572/572 [01:18<00:00,  7.32it/s]\n","[1 / 10]   Val: Loss = 0.21373, Accuracy = 92.50%: 100%|██████████| 13/13 [00:07<00:00,  1.85it/s]\n","[2 / 10] Train: Loss = 0.16781, Accuracy = 93.79%: 100%|██████████| 572/572 [01:18<00:00,  7.31it/s]\n","[2 / 10]   Val: Loss = 0.18348, Accuracy = 93.71%: 100%|██████████| 13/13 [00:07<00:00,  1.82it/s]\n","[3 / 10] Train: Loss = 0.12919, Accuracy = 94.92%: 100%|██████████| 572/572 [01:17<00:00,  7.34it/s]\n","[3 / 10]   Val: Loss = 0.17585, Accuracy = 92.88%: 100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n","[4 / 10] Train: Loss = 0.11444, Accuracy = 95.32%: 100%|██████████| 572/572 [01:18<00:00,  7.27it/s]\n","[4 / 10]   Val: Loss = 0.18039, Accuracy = 92.58%: 100%|██████████| 13/13 [00:07<00:00,  1.85it/s]\n","[5 / 10] Train: Loss = 0.10827, Accuracy = 95.45%: 100%|██████████| 572/572 [01:18<00:00,  7.30it/s]\n","[5 / 10]   Val: Loss = 0.17309, Accuracy = 93.52%: 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]\n","[6 / 10] Train: Loss = 0.10524, Accuracy = 95.51%: 100%|██████████| 572/572 [01:17<00:00,  7.33it/s]\n","[6 / 10]   Val: Loss = 0.17616, Accuracy = 93.90%: 100%|██████████| 13/13 [00:06<00:00,  1.92it/s]\n","[7 / 10] Train: Loss = 0.10376, Accuracy = 95.54%: 100%|██████████| 572/572 [01:18<00:00,  7.29it/s]\n","[7 / 10]   Val: Loss = 0.17689, Accuracy = 92.86%: 100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n","[8 / 10] Train: Loss = 0.10274, Accuracy = 95.55%: 100%|██████████| 572/572 [01:17<00:00,  7.39it/s]\n","[8 / 10]   Val: Loss = 0.17159, Accuracy = 93.84%: 100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n","[9 / 10] Train: Loss = 0.10191, Accuracy = 95.59%: 100%|██████████| 572/572 [01:18<00:00,  7.32it/s]\n","[9 / 10]   Val: Loss = 0.18591, Accuracy = 92.70%: 100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n","[10 / 10] Train: Loss = 0.10164, Accuracy = 95.59%: 100%|██████████| 572/572 [01:17<00:00,  7.40it/s]\n","[10 / 10]   Val: Loss = 0.17285, Accuracy = 93.61%: 100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"m0qGetIhfUE5"},"source":["### Masking\n","\n","**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n","\n","У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."]},{"cell_type":"code","metadata":{"id":"kFfEaQySEi65"},"source":["#DONE Implement masking"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAfV2dEOfHo5"},"source":["**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98wr38_rw55D","executionInfo":{"status":"ok","timestamp":1620462658106,"user_tz":-420,"elapsed":15045,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"1e63a725-e203-41f6-c093-cf1a6fd97f30"},"source":["\n","#X_flat_test, y_flat_test = torch.cuda.LongTensor(np.hstack(X_test)).unsqueeze(1), torch.cuda.LongTensor(np.hstack(y_batch_test)).unsqueeze(1)\n","#X_batch_test, y_batch_test = next(iterate_batches((X_test, y_test), len(X_test)))\n","batch_size=64\n","batches_count = math.ceil(len(X_test) / batch_size)\n","accuracy=0\n","for i, (X_batch, y_batch) in enumerate(iterate_batches((X_test, y_test),batch_size)):\n","  X_batch_test,y_batch_test=LongTensor(X_batch),LongTensor(y_batch)\n","  logits = model(X_batch_test)\n","  _, target = torch.max(logits, 1)\n","  accuracy += accuracy_lstm(y_batch_test,target)/batches_count\n","print('Accuracy of trained lstm tagger = {:.2%}'.format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of trained lstm tagger = 93.63%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PXUTSFaEHbDG"},"source":["### Bidirectional LSTM\n","\n","Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n","\n","![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n","*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n","\n","**Задание** Добавьте Bidirectional LSTM."]},{"cell_type":"code","metadata":{"id":"qgHUyDb3M5kY"},"source":["class bdLSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.lstm_hidden_dim = lstm_hidden_dim\n","        self.lstm_layers_count = lstm_layers_count\n","        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, bidirectional=True)\n","        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n","\n","    def forward(self, inputs):\n","        tag_scores=[]\n","        for i in range(len(inputs)):\n","          embeds = self.word_embeddings(inputs[i])\n","          lstm_out, _ = self.lstm(embeds.view(len(inputs[i]), 1, -1))\n","          tag_space = self.hidden2tag(lstm_out.view(len(inputs[i]), -1))\n","          tag_scores.append(F.log_softmax(tag_space, dim=1))\n","        return torch.transpose(torch.stack(tag_scores,0),1,2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nqnd-t3BIK_-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620465872165,"user_tz":-420,"elapsed":736440,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"ecb97e63-7c24-4db4-bc02-3cd8bc7fddc9"},"source":["model = bdLSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0).cuda()\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=5,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 / 5] Train: Loss = 0.67751, Accuracy = 77.60%: 100%|██████████| 572/572 [02:14<00:00,  4.24it/s]\n","[1 / 5]   Val: Loss = 0.36801, Accuracy = 87.55%: 100%|██████████| 13/13 [00:14<00:00,  1.08s/it]\n","[2 / 5] Train: Loss = 0.30079, Accuracy = 89.78%: 100%|██████████| 572/572 [02:13<00:00,  4.30it/s]\n","[2 / 5]   Val: Loss = 0.25790, Accuracy = 91.27%: 100%|██████████| 13/13 [00:13<00:00,  1.05s/it]\n","[3 / 5] Train: Loss = 0.22065, Accuracy = 92.31%: 100%|██████████| 572/572 [02:13<00:00,  4.30it/s]\n","[3 / 5]   Val: Loss = 0.21606, Accuracy = 92.27%: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]\n","[4 / 5] Train: Loss = 0.18136, Accuracy = 93.43%: 100%|██████████| 572/572 [02:14<00:00,  4.27it/s]\n","[4 / 5]   Val: Loss = 0.19388, Accuracy = 93.21%: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n","[5 / 5] Train: Loss = 0.15776, Accuracy = 94.12%: 100%|██████████| 572/572 [02:12<00:00,  4.32it/s]\n","[5 / 5]   Val: Loss = 0.17930, Accuracy = 93.52%: 100%|██████████| 13/13 [00:14<00:00,  1.09s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ZTXmYGD_ANhm"},"source":["### Предобученные эмбеддинги\n","\n","Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n","\n","Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"]},{"cell_type":"code","metadata":{"id":"uZpY_Q1xZ18h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620467301483,"user_tz":-420,"elapsed":78831,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"bfcf2c42-ea43-473b-8036-a68792d55dd6"},"source":["import gensim.downloader as api\n","\n","w2v_model = api.load('glove-wiki-gigaword-100')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KYogOoKlgtcf"},"source":["Построим подматрицу для слов из нашей тренировочной выборки:"]},{"cell_type":"code","metadata":{"id":"VsCstxiO03oT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620467361803,"user_tz":-420,"elapsed":802,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"094766a0-4cba-42f2-eff3-8fa7b15ceb89"},"source":["known_count = 0\n","embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n","for word, ind in word2ind.items():\n","    word = word.lower()\n","    if word in w2v_model.vocab:\n","        embeddings[ind] = w2v_model.get_vector(word)\n","        known_count += 1\n","        \n","print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Know 38736 out of 45441 word embeddings\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HcG7i-R8hbY3"},"source":["**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."]},{"cell_type":"code","metadata":{"id":"LxaRBpQd0pat"},"source":["class LSTMTaggerWithPretrainedEmbs(nn.Module):\n","    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n","        super().__init__()\n","        #DONE Implement pretrained embedding\n","        self.lstm_hidden_dim = lstm_hidden_dim\n","        self.lstm_layers_count = lstm_layers_count\n","        self.word_embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(embeddings))\n","        self.lstm = nn.LSTM(torch.FloatTensor(embeddings).size()[1], lstm_hidden_dim, bidirectional=True)\n","        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n","\n","\n","    def forward(self, inputs):\n","        tag_scores=[]\n","        for i in range(len(inputs)):\n","          embeds = self.word_embeddings(inputs[i])\n","          lstm_out, _ = self.lstm(embeds.view(len(inputs[i]), 1, -1))\n","          tag_space = self.hidden2tag(lstm_out.view(len(inputs[i]), -1))\n","          tag_scores.append(F.log_softmax(tag_space, dim=1))\n","        return torch.transpose(torch.stack(tag_scores,0),1,2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBtI6BDE-Fc7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620480890640,"user_tz":-420,"elapsed":1908259,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"f44db483-36a0-4da7-b73e-129b6d75b814"},"source":["model = LSTMTaggerWithPretrainedEmbs(\n","    embeddings=embeddings,\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(),lr=5e-3)\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=15,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 / 15] Train: Loss = 0.31321, Accuracy = 89.99%: 100%|██████████| 572/572 [01:56<00:00,  4.92it/s]\n","[1 / 15]   Val: Loss = 0.20694, Accuracy = 92.98%: 100%|██████████| 13/13 [00:12<00:00,  1.08it/s]\n","[2 / 15] Train: Loss = 0.17354, Accuracy = 93.75%: 100%|██████████| 572/572 [01:54<00:00,  4.98it/s]\n","[2 / 15]   Val: Loss = 0.19404, Accuracy = 92.82%: 100%|██████████| 13/13 [00:12<00:00,  1.08it/s]\n","[3 / 15] Train: Loss = 0.16072, Accuracy = 93.99%: 100%|██████████| 572/572 [01:55<00:00,  4.97it/s]\n","[3 / 15]   Val: Loss = 0.18482, Accuracy = 93.33%: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n","[4 / 15] Train: Loss = 0.15478, Accuracy = 94.12%: 100%|██████████| 572/572 [01:55<00:00,  4.97it/s]\n","[4 / 15]   Val: Loss = 0.18432, Accuracy = 93.23%: 100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n","[5 / 15] Train: Loss = 0.15078, Accuracy = 94.19%: 100%|██████████| 572/572 [01:54<00:00,  4.98it/s]\n","[5 / 15]   Val: Loss = 0.17900, Accuracy = 93.42%: 100%|██████████| 13/13 [00:11<00:00,  1.08it/s]\n","[6 / 15] Train: Loss = 0.14781, Accuracy = 94.27%: 100%|██████████| 572/572 [01:55<00:00,  4.95it/s]\n","[6 / 15]   Val: Loss = 0.17543, Accuracy = 93.58%: 100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n","[7 / 15] Train: Loss = 0.14576, Accuracy = 94.31%: 100%|██████████| 572/572 [01:54<00:00,  5.00it/s]\n","[7 / 15]   Val: Loss = 0.17647, Accuracy = 93.54%: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]\n","[8 / 15] Train: Loss = 0.14397, Accuracy = 94.32%: 100%|██████████| 572/572 [01:55<00:00,  4.97it/s]\n","[8 / 15]   Val: Loss = 0.17585, Accuracy = 93.44%: 100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n","[9 / 15] Train: Loss = 0.14210, Accuracy = 94.38%: 100%|██████████| 572/572 [01:55<00:00,  4.96it/s]\n","[9 / 15]   Val: Loss = 0.17574, Accuracy = 93.44%: 100%|██████████| 13/13 [00:12<00:00,  1.06it/s]\n","[10 / 15] Train: Loss = 0.14127, Accuracy = 94.40%: 100%|██████████| 572/572 [01:54<00:00,  4.97it/s]\n","[10 / 15]   Val: Loss = 0.17526, Accuracy = 93.17%: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n","[11 / 15] Train: Loss = 0.14031, Accuracy = 94.42%: 100%|██████████| 572/572 [01:54<00:00,  5.00it/s]\n","[11 / 15]   Val: Loss = 0.17523, Accuracy = 93.45%: 100%|██████████| 13/13 [00:11<00:00,  1.12it/s]\n","[12 / 15] Train: Loss = 0.13931, Accuracy = 94.46%: 100%|██████████| 572/572 [01:55<00:00,  4.94it/s]\n","[12 / 15]   Val: Loss = 0.17287, Accuracy = 93.56%: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]\n","[13 / 15] Train: Loss = 0.13834, Accuracy = 94.47%: 100%|██████████| 572/572 [01:54<00:00,  5.00it/s]\n","[13 / 15]   Val: Loss = 0.17116, Accuracy = 93.58%: 100%|██████████| 13/13 [00:12<00:00,  1.08it/s]\n","[14 / 15] Train: Loss = 0.13769, Accuracy = 94.48%: 100%|██████████| 572/572 [01:55<00:00,  4.95it/s]\n","[14 / 15]   Val: Loss = 0.17323, Accuracy = 93.57%: 100%|██████████| 13/13 [00:12<00:00,  1.07it/s]\n","[15 / 15] Train: Loss = 0.13674, Accuracy = 94.52%: 100%|██████████| 572/572 [01:55<00:00,  4.95it/s]\n","[15 / 15]   Val: Loss = 0.17336, Accuracy = 93.52%: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ux6udEDrM1ez","executionInfo":{"status":"ok","timestamp":1620482688013,"user_tz":-420,"elapsed":632215,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"ff062563-56de-4a54-bfee-6afb23ddae2f"},"source":["criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(),lr=5e-4)\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=5,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 / 5] Train: Loss = 0.12714, Accuracy = 94.81%: 100%|██████████| 572/572 [01:54<00:00,  5.01it/s]\n","[1 / 5]   Val: Loss = 0.16667, Accuracy = 93.67%: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n","[2 / 5] Train: Loss = 0.12604, Accuracy = 94.84%: 100%|██████████| 572/572 [01:54<00:00,  5.01it/s]\n","[2 / 5]   Val: Loss = 0.16672, Accuracy = 93.68%: 100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n","[3 / 5] Train: Loss = 0.12556, Accuracy = 94.84%: 100%|██████████| 572/572 [01:54<00:00,  5.00it/s]\n","[3 / 5]   Val: Loss = 0.16551, Accuracy = 93.68%: 100%|██████████| 13/13 [00:11<00:00,  1.14it/s]\n","[4 / 5] Train: Loss = 0.12562, Accuracy = 94.86%: 100%|██████████| 572/572 [01:54<00:00,  4.99it/s]\n","[4 / 5]   Val: Loss = 0.16570, Accuracy = 93.67%: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]\n","[5 / 5] Train: Loss = 0.12517, Accuracy = 94.86%: 100%|██████████| 572/572 [01:54<00:00,  5.00it/s]\n","[5 / 5]   Val: Loss = 0.16631, Accuracy = 93.67%: 100%|██████████| 13/13 [00:11<00:00,  1.15it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2Ne_8f24h8kg"},"source":["**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n","\n","Добейтесь качества лучше прошлых моделей."]},{"cell_type":"code","metadata":{"id":"HPUuAPGhEGVR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620482988298,"user_tz":-420,"elapsed":21511,"user":{"displayName":"Богдан Дмитриевич Куценко","photoUrl":"","userId":"02999085941421133790"}},"outputId":"5e1fda67-168a-4837-dfea-eb1d55985506"},"source":["batch_size=64\n","batches_count = math.ceil(len(X_test) / batch_size)\n","accuracy=0\n","for i, (X_batch, y_batch) in enumerate(iterate_batches((X_test, y_test),batch_size)):\n","  X_batch_test,y_batch_test=LongTensor(X_batch),LongTensor(y_batch)\n","  logits = model(X_batch_test)\n","  _, target = torch.max(logits, 1)\n","  accuracy += accuracy_lstm(y_batch_test,target)/batches_count\n","print('Accuracy of trained lstm tagger = {:.2%}'.format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of trained lstm tagger = 93.72%\n"],"name":"stdout"}]}]}